{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python code to classify text into known text categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code takes a .json file as input. The file should contain two columns - a \"lyrics\" column containing lyrics and a \"song\" column containing the song label.\n",
    "\n",
    "Lexical similarity. \n",
    "\n",
    "Won't capture if similar words, not identical. \n",
    "Lexical similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              lyrics          song\n",
      "0  Cause, baby, now we got bad bloodYou know it u...     bad_blood\n",
      "1  You know it used to be mad love (mad love)So t...     bad_blood\n",
      "2  Nice to meet you, where you been?I could show ...   blank_space\n",
      "3  Got a long list of ex-loversTheyll tell you Im...   blank_space\n",
      "4  Cause were young and were recklessWell take th...   blank_space\n",
      "5  I stay out too lateGot nothing in my brainThat...  shake_it_off\n",
      "6  Im dancing on my own (dancing on my own)I make...  shake_it_off\n",
      "7  Shes like Oh, my god! but Im just gonna shake....  shake_it_off\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Load in text data, split into train/test \n",
    "#==============================================================================\n",
    "\n",
    "# load in data\n",
    "os.chdir(\"/Users/natashal/Projects/random_things/hack_cambridge/swift_lyrics/\")\n",
    "# lyrics = pd.read_json('swift.json') # works\n",
    "lyrics = pd.read_json('dataset_swift3.json')\n",
    "\n",
    "print lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.head of                                               lyrics          song\n",
       "0  Cause, baby, now we got bad bloodYou know it u...     bad_blood\n",
       "1  You know it used to be mad love (mad love)So t...     bad_blood\n",
       "2  Nice to meet you, where you been?I could show ...   blank_space\n",
       "3  Got a long list of ex-loversTheyll tell you Im...   blank_space\n",
       "4  Cause were young and were recklessWell take th...   blank_space\n",
       "5  I stay out too lateGot nothing in my brainThat...  shake_it_off\n",
       "6  Im dancing on my own (dancing on my own)I make...  shake_it_off\n",
       "7  Shes like Oh, my god! but Im just gonna shake....  shake_it_off>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's the shape (rows, columns) of the data?\n",
    "print(lyrics.shape); type(lyrics)\n",
    "lyrics.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "# drop entries with null values, check shape afterwards\n",
    "lyrics = lyrics.dropna(how='any')\n",
    "lyrics.shape\n",
    "\n",
    "# split my data into train and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "train, test = train_test_split(lyrics, test_size=0.2, random_state=42)\n",
    "print train.shape; print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset(['all', 'six', 'less', 'being', 'indeed', 'over', 'move', 'anyway', 'four', 'not', 'own', 'through', 'yourselves', 'fify', 'where', 'mill', 'only', 'find', 'before', 'one', 'whose', 'system', 'how', 'somewhere', 'with', 'thick', 'show', 'had', 'enough', 'should', 'to', 'must', 'whom', 'seeming', 'under', 'ours', 'has', 'might', 'thereafter', 'latterly', 'do', 'them', 'his', 'around', 'than', 'get', 'very', 'de', 'none', 'cannot', 'every', 'whether', 'they', 'front', 'during', 'thus', 'now', 'him', 'nor', 'name', 'several', 'hereafter', 'always', 'who', 'cry', 'whither', 'this', 'someone', 'either', 'each', 'become', 'thereupon', 'sometime', 'side', 'two', 'therein', 'twelve', 'because', 'often', 'ten', 'our', 'eg', 'some', 'back', 'up', 'go', 'namely', 'towards', 'are', 'further', 'beyond', 'ourselves', 'yet', 'out', 'even', 'will', 'what', 'still', 'for', 'bottom', 'mine', 'since', 'please', 'forty', 'per', 'its', 'everything', 'behind', 'un', 'above', 'between', 'it', 'neither', 'seemed', 'ever', 'across', 'she', 'somehow', 'be', 'we', 'full', 'never', 'sixty', 'however', 'here', 'otherwise', 'were', 'whereupon', 'nowhere', 'although', 'found', 'alone', 're', 'along', 'fifteen', 'by', 'both', 'about', 'last', 'would', 'anything', 'via', 'many', 'could', 'thence', 'put', 'against', 'keep', 'etc', 'amount', 'became', 'ltd', 'hence', 'onto', 'or', 'con', 'among', 'already', 'co', 'afterwards', 'formerly', 'within', 'seems', 'into', 'others', 'while', 'whatever', 'except', 'down', 'hers', 'everyone', 'done', 'least', 'another', 'whoever', 'moreover', 'couldnt', 'throughout', 'anyhow', 'yourself', 'three', 'from', 'her', 'few', 'together', 'top', 'there', 'due', 'been', 'next', 'anyone', 'eleven', 'much', 'call', 'therefore', 'interest', 'then', 'thru', 'themselves', 'hundred', 'was', 'sincere', 'empty', 'more', 'himself', 'elsewhere', 'mostly', 'on', 'fire', 'am', 'becoming', 'hereby', 'amongst', 'else', 'part', 'everywhere', 'too', 'herself', 'former', 'those', 'he', 'me', 'myself', 'made', 'twenty', 'these', 'bill', 'cant', 'us', 'until', 'besides', 'nevertheless', 'below', 'anywhere', 'nine', 'can', 'of', 'your', 'toward', 'my', 'something', 'and', 'whereafter', 'whenever', 'give', 'almost', 'wherever', 'is', 'describe', 'beforehand', 'herein', 'an', 'as', 'itself', 'at', 'have', 'in', 'seem', 'whence', 'ie', 'any', 'fill', 'again', 'hasnt', 'inc', 'thereby', 'thin', 'no', 'perhaps', 'latter', 'meanwhile', 'when', 'detail', 'same', 'wherein', 'beside', 'also', 'that', 'other', 'take', 'which', 'becomes', 'you', 'if', 'nobody', 'see', 'though', 'may', 'after', 'upon', 'most', 'hereupon', 'eight', 'but', 'serious', 'nothing', 'such', 'why', 'a', 'off', 'whereby', 'third', 'i', 'whole', 'noone', 'sometimes', 'well', 'amoungst', 'yours', 'their', 'rather', 'without', 'so', 'five', 'the', 'first', 'whereas', 'once'])\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Process description fields of train set\n",
    "#==============================================================================\n",
    "\n",
    "# tokenize the text using countvectoriser\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(lowercase=True, stop_words='english', strip_accents='unicode')\n",
    "print count_vect.get_stop_words()\n",
    "\n",
    "# if wanting to use n-grams\n",
    "count_vect = CountVectorizer(analyzer='word', ngram_range=(1,2), lowercase=True, stop_words='english', strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Cause, baby, now we got bad bloodYou know it ...</td>\n",
       "      <td>bad_blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>She's like \"Oh, my god!\" but I'm just gonna sh...</td>\n",
       "      <td>shake_it_off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nice to meet you, where you been?I could show ...</td>\n",
       "      <td>blank_space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Cause we're young and we're recklessWe'll tak...</td>\n",
       "      <td>blank_space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Got a long list of ex-loversThey'll tell you I...</td>\n",
       "      <td>blank_space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm dancing on my own (dancing on my own)I mak...</td>\n",
       "      <td>shake_it_off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics          song\n",
       "0  'Cause, baby, now we got bad bloodYou know it ...     bad_blood\n",
       "7  She's like \"Oh, my god!\" but I'm just gonna sh...  shake_it_off\n",
       "2  Nice to meet you, where you been?I could show ...   blank_space\n",
       "4  'Cause we're young and we're recklessWe'll tak...   blank_space\n",
       "3  Got a long list of ex-loversThey'll tell you I...   blank_space\n",
       "6  I'm dancing on my own (dancing on my own)I mak...  shake_it_off"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'alright', u'baby', u'baby couldn', u'baby got', u'baby just', u'baby queenfind', u'baby shake', u'babyand', u'babyand ll', u'bad']\n",
      "(6, 368)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.04309764,  0.        ,  0.        ,  0.03112586,  0.        ,\n",
       "          0.03112586,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.08774353],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.06364579,  0.06364579,  0.        ],\n",
       "        [ 0.10244002,  0.        ,  0.        ,  0.        ,  0.1479679 ,\n",
       "          0.        ,  0.12133579,  0.12133579,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the count vectoriser\n",
    "X_train_counts = count_vect.fit_transform(train.lyrics)\n",
    "X_train_counts.shape\n",
    "print count_vect.get_feature_names()[0:10]\n",
    "\n",
    "# get term frequencies (tf), scale by inverse document frequenies (idf)\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True, smooth_idf=True)\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print X_train_tfidf.shape\n",
    "\n",
    "# explore the matrix by converting back to dense format\n",
    "dense=X_train_tfidf.todense()\n",
    "dense[1:10, 1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 368)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.04309764,  0.        ,  0.        ,  0.03112586,  0.        ,\n",
       "          0.03112586,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.08774353],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.06364579,  0.06364579,  0.        ],\n",
       "        [ 0.10244002,  0.        ,  0.        ,  0.        ,  0.1479679 ,\n",
       "          0.        ,  0.12133579,  0.12133579,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'blank_space' u'shake_it_off']\n",
      "1       bad_blood\n",
      "5    shake_it_off\n",
      "Name: song, dtype: object\n",
      "1    False\n",
      "5    False\n",
      "Name: lyrics, dtype: bool\n",
      "('NB accuracy', 0.0)\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Training classifiers \n",
    "#==============================================================================\n",
    "###################### 1) Start with naive bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier_NB = MultinomialNB()\n",
    "# train NB classifier\n",
    "classifier_NB_fit = classifier_NB.fit(X_train_tfidf, train.song)\n",
    "                    \n",
    "# predict ratings on test set using model                    \n",
    "test_counts = count_vect.transform(test.lyrics)\n",
    "test_tfidf = tfidf_transformer.transform(test_counts)\n",
    "predicted_nb = classifier_NB_fit.predict(test_tfidf)\n",
    "print predicted_nb\n",
    "print test.song\n",
    "\n",
    "## get accuracy i.e. how often the predicted value eqausl the target values\n",
    "print(\"NB accuracy\", np.mean(predicted_nb == test.lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'bad_blood' u'shake_it_off']\n",
      "1       bad_blood\n",
      "5    shake_it_off\n",
      "Name: song, dtype: object\n",
      "('SVM accuracy', 1.0)\n"
     ]
    }
   ],
   "source": [
    "####################### 2) Train the linear SVM \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier_svm = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "classifier_svm_fit = classifier_svm.fit(X_train_tfidf, train.song)                               \n",
    "                               \n",
    "# predict ratings on test set using model\n",
    "predicted_svm = classifier_svm_fit.predict(test_tfidf) \n",
    "\n",
    "# get accuracy again, to compare to NB\n",
    "print(\"SVM accuracy\", np.mean(predicted_svm == test.song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  bad_blood       1.00      1.00      1.00         1\n",
      "shake_it_off       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       1.00      1.00      1.00         2\n",
      "\n",
      "[[1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Detailed performance metrics\n",
    "#==============================================================================\n",
    "# write out classification performance report\n",
    "from sklearn import metrics\n",
    "report = metrics.classification_report(test.song, predicted_svm)\n",
    "print(report)\n",
    "\n",
    "# write out confusion matrix\n",
    "confusion = metrics.confusion_matrix(test.song, predicted_svm)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a8ad3b00baf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Normalize the confusion matrix by row (i.e by the number of samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion' is not defined"
     ]
    }
   ],
   "source": [
    "### NOT TESTED\n",
    "# DONT RUN THIS YET\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, title=\"Confusion matrix\"):\n",
    "    plt.matshow(confusion_matrix) \n",
    "    plt.xticks([0, 1, 2, 3, 4], [1, 2, 3, 4, 5])\n",
    "    plt.yticks([0, 1, 2, 3, 4], [1, 2, 3, 4, 5])\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plot_confusion_matrix(confusion)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "confusion_normalized = confusion.astype('float') / confusion.sum(axis=1)[:, np.newaxis]\n",
    "print(confusion_normalized)\n",
    "plot_confusion_matrix(confusion_normalized, title=\"Normalised confusion matrix\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
